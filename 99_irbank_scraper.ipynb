{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "from threading import Thread\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import io\n",
    "from datetime import date\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_pdf_url(pdf_url):\n",
    "    web_response = requests.get(pdf_url, timeout = (3.0, 7.5))\n",
    "    pdf_datastream = io.BytesIO(web_response.content)\n",
    "\n",
    "    with pymupdf.open(stream = pdf_datastream) as pdf_doc:\n",
    "        pdf_text = [\" \" + unicodedata.normalize(\"NFKC\", \"\".join(pdf_page.get_text().splitlines())).replace(\" \", \"\") for pdf_page in pdf_doc]\n",
    "    return pdf_text\n",
    "\n",
    "def get_list_emptiness(list_targets, threshold = 0.5):\n",
    "    return(sum([(len(list_target) > 0) for list_target in list_targets]) > (threshold * len(list_targets)))\n",
    "\n",
    "def search_ir_reports(stock_code, search_words = [\"中期経営\", \"中期戦略\"]):\n",
    "    search_url = \"https://irbank.net/td/search?q=\"\n",
    "    df_result = pd.DataFrame()\n",
    "\n",
    "    for search_word in search_words:\n",
    "        list_file_name = []\n",
    "        list_file_date = []\n",
    "        list_file_name_num = []\n",
    "        list_file_link = []\n",
    "        list_file_content = []\n",
    "        list_file_content_readable = []\n",
    "\n",
    "        search_soup = BeautifulSoup(requests.get(search_url + search_word + \" \" + str(stock_code)).content, \"html.parser\")\n",
    "        search_links = search_soup.select(\"td:last-child > a\")\n",
    "\n",
    "        for search_link in search_links:\n",
    "            file_name = search_link.text\n",
    "            list_file_name.append(file_name)\n",
    "            list_file_name_num.append(\"_\".join([str(s) for s in re.findall(r\"\\d+\", file_name)]))\n",
    "\n",
    "            file_date = search_link.parent.parent.find_previous_sibling(\"tr\", class_ = \"occ\").text\n",
    "            file_date = [int(s) for s in re.findall(r\"\\d+\", file_date)]\n",
    "            file_date = date(file_date[0], file_date[1], file_date[2])\n",
    "            list_file_date.append(file_date)\n",
    "\n",
    "            subpage_link = urljoin(search_url, search_link.get(\"href\"))\n",
    "            subpage_soup = BeautifulSoup(requests.get(subpage_link).content, \"html.parser\")\n",
    "\n",
    "            try: file_link = subpage_soup.select(\".fa-file-pdf\")[0].parent.get(\"href\")\n",
    "            except: file_link = \"\"\n",
    "            if list_file_link:\n",
    "                file_content = []\n",
    "                file_content_readable = False\n",
    "            else:\n",
    "                try:\n",
    "                    file_content = get_text_from_pdf_url(file_link)\n",
    "                    file_content_readable = get_list_emptiness(file_content)\n",
    "                except:\n",
    "                    file_content = []\n",
    "                    file_content_readable = False\n",
    "            list_file_link.append(file_link)\n",
    "            list_file_content.append(file_content)\n",
    "            list_file_content_readable.append(file_content_readable)\n",
    "        \n",
    "        df_temp = pd.DataFrame({\"file_name\": list_file_name, \"file_date\": list_file_date, \"file_name_num\": list_file_name_num, \"file_link\": list_file_link, \"file_content\": list_file_content, \"file_content_readable\": list_file_content_readable})\n",
    "        df_temp[\"search_word\"] = search_word\n",
    "\n",
    "        if len(df_result) == 0: df_result = df_temp\n",
    "        else: df_result = pd.concat([df_result, df_temp])\n",
    "        if len(df_temp) > 0: continue\n",
    "\n",
    "    df_result[\"stock_code\"] = stock_code\n",
    "    df_result = df_result[[\"stock_code\", \"search_word\", \"file_name\", \"file_date\", \"file_name_num\", \"file_link\", \"file_content\", \"file_content_readable\"]].drop_duplicates(subset = \"file_link\")\n",
    "\n",
    "    return df_result\n",
    "\n",
    "def get_irbank_reports(list_stock_code, track_progress = False):\n",
    "    df_irbank_report = pd.DataFrame()\n",
    "\n",
    "    if track_progress:\n",
    "        for stock_code in tqdm(list_stock_code):\n",
    "            df_temp = search_ir_reports(stock_code)\n",
    "            if len(df_irbank_report) == 0: df_irbank_report = df_temp\n",
    "            else: df_irbank_report = pd.concat([df_irbank_report, df_temp])\n",
    "    else:\n",
    "        for stock_code in list_stock_code:\n",
    "            df_temp = search_ir_reports(stock_code)\n",
    "            if len(df_irbank_report) == 0: df_irbank_report = df_temp\n",
    "            else: df_irbank_report = pd.concat([df_irbank_report, df_temp])\n",
    "    \n",
    "    return df_irbank_report\n",
    "\n",
    "def irbank_thread(thread_num, thread_count = 10, company_list_file = \"00_company_list.xlsx\", company_list_sheet = \"対象企業リスト\"):\n",
    "    df_company = pd.read_excel(company_list_file, sheet_name = company_list_sheet)\n",
    "    df_company = df_company.rename(columns = {\"証券コード\": \"stock_code\", \"企業名\": \"company_name\"})\n",
    "    df_company.astype({\"stock_code\": \"str\"})\n",
    "    list_stock_code = list(df_company[\"stock_code\"])\n",
    "    thread_length = int(len(list_stock_code) / thread_count)\n",
    "    if thread_num != thread_count: list_stock_code_thread =  list_stock_code[thread_length * (thread_num - 1):thread_length * thread_num]\n",
    "    else: list_stock_code_thread =  list_stock_code[thread_length * (thread_num - 1):]\n",
    "    if thread_num == 1: df_thread = get_irbank_reports(list_stock_code_thread, track_progress = True)\n",
    "    else: df_thread = get_irbank_reports(list_stock_code_thread)\n",
    "    df_thread.to_feather(\"99_irbank_thread_\" + str(thread_num) + \".arrow\")\n",
    "\n",
    "class ThreadClass:\n",
    "    def irbank_thread_1():  irbank_thread(1)\n",
    "    def irbank_thread_2():  irbank_thread(2)\n",
    "    def irbank_thread_3():  irbank_thread(3)\n",
    "    def irbank_thread_4():  irbank_thread(4)\n",
    "    def irbank_thread_5():  irbank_thread(5)\n",
    "    def irbank_thread_6():  irbank_thread(6)\n",
    "    def irbank_thread_7():  irbank_thread(7)\n",
    "    def irbank_thread_8():  irbank_thread(8)\n",
    "    def irbank_thread_9():  irbank_thread(9)\n",
    "    def irbank_thread_10(): irbank_thread(10)\n",
    "\n",
    "def combine_irbank_threads(company_list_file = \"00_company_list.xlsx\", company_list_sheet = \"対象企業リスト\"):\n",
    "    thread_functions = [method for method in dir(ThreadClass) if callable(getattr(ThreadClass, method)) and not method.startswith(\"__\")]\n",
    "    threads = [Thread(target = getattr(ThreadClass, thread_function)) for thread_function in thread_functions]\n",
    "    for thread in threads: thread.start()\n",
    "    for thread in threads: thread.join()\n",
    "\n",
    "    df_combined = pd.DataFrame()\n",
    "    for thread_num in range(len(thread_functions)):\n",
    "        df_thread = pd.read_feather(\"99_irbank_thread_\" + str(thread_num + 1) + \".arrow\")\n",
    "        if len(df_combined) == 0: df_combined = df_thread\n",
    "        else: df_combined = pd.concat([df_combined, df_thread])\n",
    "    df_short = df_combined.drop_duplicates(subset = \"stock_code\")\n",
    "    df_combined = df_combined.drop([\"file_content\", \"file_content_readable\"], axis = 1)\n",
    "\n",
    "    df_company = pd.read_excel(company_list_file, sheet_name = company_list_sheet)\n",
    "    df_company = df_company.rename(columns = {\"証券コード\": \"stock_code\", \"企業名\": \"company_name\"})\n",
    "    df_short = pd.merge(df_company, df_short, on = \"stock_code\", how = \"left\")\n",
    "    df_short = df_short.explode(\"file_content\")\n",
    "\n",
    "    df_combined.to_feather(\"99_irbank_thread_long.arrow\")\n",
    "    df_short.to_feather(\"99_irbank_thread_short.arrow\")\n",
    "    for thread_num in range(len(thread_functions)):\n",
    "        os.remove(\"99_irbank_thread_\" + str(thread_num + 1) + \".arrow\")\n",
    "\n",
    "    with pd.ExcelWriter(\"01_irbank_results.xlsx\") as writer:\n",
    "        df_combined.to_excel(writer, sheet_name = \"df_long\", index = False)\n",
    "        df_short.to_excel(writer, sheet_name = \"df_short\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/393 [00:16<08:46,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cycle in structure tree\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 117/393 [03:31<04:55,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cycle in structure tree\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [11:02<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "combine_irbank_threads()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
